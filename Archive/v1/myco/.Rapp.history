y <- rexp(n=10,rate=0.08)#
#
# bounds for the prior#
a <- 0.01 # min for prior#
b <- 0.20 # max for prior#
#
# the range of parameters for lambda that we're going to search in#
rseq <- seq(0, 0.30, length=200)#
#
# the prior is a density function that is uniformly distributed from a to b#
prior <- dunif(rseq,min=a, max=b) #
#
# pre allocating a vector that the likelihood values will go into#
likeVal <- rep(0,200)#
#
# for each point in the dataset, we want to find the likelihood for all values of rseq. #
for(i in 1:length(y)) # loop through each data point#
	{#
	likeVal <- likeVal + dexp(y[i], rate=rseq, log=TRUE) # #
		}#
likeVal <- exp(likeVal)/sum(exp(likeVal))/diff(rseq)[1]
post <- rep(0,200)#
for(i in 1:length(y))#
	{#
	post <- dexp(rseq,likeVal*prior)	#
		}
post
post2 <- dexp(rseq,likeVal*prior)
post2
?dexp
y <- rexp(n=10, rate=0.08)
y
hist(y,10)
hist(y)
?hist
hist(y,breaks=10)
hist(y,breaks=3)
y
a <- 0.01 # min for prior
b <- 0.20 # max for prior
rseq <- seq(0, 0.30, length=200)
prior <- dunif(rseq,min=a, max=b)
5.6978-2
3.6978/3.7015
n <- 10
y <- round(rexp(n,.1))
y
rhomle <- 1/mean(y); rhomle
-n*log(rhomle) + rhomle*sum(y)
rseq <- seq(0.01,.4,length=100)
rseq
lkexp <- function(rho) {-n*log(rho) + rho*sum(y)}
lkexp
plot(rseq,lkexp(rseq),type='l')
abline(v=rhomle, lty=2)
plot(rseq,lkexp(rseq),type='l')
abline(v=rhomle, lty=2)
abline(h=lkexp(rhomle),lty=2)
plot(rseq,lkexp(rseq),type='l', xlab="-lnL", ylab="MLE")
abline(v=rhomle, lty=2)
abline(h=lkexp(rhomle),lty=2)
fit <- optimize(lkexp,lower=0.01,upper=0.5,maximum=F)
fit
fit$objective
fit$minimum
lr <- -lkexp(rseq) + fit$objective
fit <- optimize(lkexp,lower=0.01,upper=0.5,maximum=F)#
fit # minimum=rho, objective=-lnL @ rhoML#
#
#########################
# Confidence intervals ##
#########################
#
# Likelihood profile#
#
# log of the likelihood ratio - the difference in log likelihood between all values in rseq and the MLE#
lr <- -lkexp(rseq) + fit$objective#
#
# relationship between likelihood ratio and deviance#
dev <- -2*lr#
#
gchisq(0.95,1)
qchisq(0.95,1)
#################################
# Maximum likelihood estimates ##
#################################
 #
# ML of 10 mortality ages, exponential distribution#
n <- 10#
y <- round(rexp(n,.1)); y#
#
#analytical solution - preferable if there is one#
rhomle <- 1/mean(y); rhomle#
#
# - log likelihood associated with the rhomle value#
-n*log(rhomle) + rhomle*sum(y)#
#
# explore the likelihood function numerically#
rseq <- seq(0.01,.4,length=100)#
#
# R function showing -log likelihood for the data#
lkexp <- function(rho) {-n*log(rho) + rho*sum(y)}#
#
# plot the function#
plot(rseq,lkexp(rseq),type='l', xlab="-lnL", ylab="MLE")#
abline(v=rhomle, lty=2)#
abline(h=lkexp(rhomle),lty=2)#
#
# numerical solution using function "optimize"#
fit <- optimize(lkexp,lower=0.01,upper=0.5,maximum=F)#
fit # minimum=rho, objective=-lnL @ rhoML#
#
#########################
# Confidence intervals ##
#########################
#
# Likelihood profile#
#
# log of the likelihood ratio - the difference in log likelihood between all values in rseq and the MLE#
lr <- -lkexp(rseq) + fit$objective#
#
# relationship between likelihood ratio and deviance#
dev <- -2*lr#
#
# quantile function for the chi square distribution. Gives the deviance for 95% confidence.#
qchisq(0.95,1)#
#
# sequence of p values for this deviance is X2 with 1 df#
p <- 1 - pchisq(dev,1)#
#
# plots for likelihood, lkhd profile, deviance:#
par(mfrow=c(3,1))#
#
plot(rseq, exp(lr), type='l') #likelihood#
	abline(v=rhomle,lty=3)#
	#
plot(rseq, dev, type='l') # deviance#
	dc <- qchisq(.95,1)	# deviance at 95%#
	abline(h=dc, lty=3)	# horizontal line at 95% conf#
	hi <- max(rseq[ dev<dc] ) # lower limit#
	lo <- min(rseq[ dev<dc] ) # upper limit#
	abline(v=c(lo, hi), lty=3)	# confidence level#
	abline(v=rhomle,lty=3)#
	#
plot(rseq,p,type='l')#
  abline(h=0.05,lty=3)#
  abline(v=c(lo,hi),lty=3)#
  #
################################
# CI using Fisher Information ##
################################
#
se <- rhomle/sqrt(n)#
#
# find the 95%tile using the quantile function for the normal distribution#
#
ci <- qnorm(c(0.025,0.975),rhomle,se)#
#
# Drawing a normal distributions centered on the confidence limits (CLs) we have #
#
low  <- dnorm(rseq,ci[1],se)#
high <- dnorm(rseq,ci[2],se)#
plot(rseq,low,type='l')#
  lines(rseq,high)#
  abline(v=ci,lty=3)#
#
###########################  #
# nonparametric bootstrap ##
############################
#
# To bootstrap parameter error, define the number of iterations and an array to hold the bootstrap estimates#
nboot <- 2000#
mle <- rep( 0, nboot)#
#
# for loop that samples from the dataset and fills the mle vector with 1/mean of the samples#
for( b in 1:nboot) {#
	a <- sample(y, n, replace=T) 	# resampled data set#
	mle[b] <- 1/mean(a)				# the bth MLE#
}#
#
# std err for b#
seb <- sd(mle); seb#
#
# CIs are quantiles#
cib <- quantile(mle, c(0.025, 0.975)); cib#
#
# histogram of parameter values#
hist( mle, nclass=20, probability=T)#
	abline( v=cib, lty=3)
library(Geneland)
install.packages("Geneland")
library(Geneland)
?geneland
?Geneland
library(Geneland)
coord.n <- coord[coord$x < 437755]
setwd("/Users/karljarvis/Documents/_NAU/Classes/R/pumas/Geneland/")
geno <- read.table("pumageno.txt")
coord <- read.table("pumacoord.txt")
colnames(coord) <- c("x","y")
coord.n <- coord[coord$x < 437755]
coord
coord$x
coord.n <- coord[coord$x]
coord.n <- coord[,coord$x]
coord.n <- coord[which(coord$x < 437755)]
coord$x
coord$x >500000
coord[5]
coord[1]
coord[10]
coord[2]
coord[3]
coord <- data.matrix(read.table("pumacoord.txt"))
coord <- data.matrix(coord)
coord[1]
coord.n <- coord[which(coord$x <437755)]
coord.n <- coord[x < 437755]
coord$x
x
coord[5,3]
coord[5,2]
coord[>5]
coord[x>5]
coord <- read.table("pumacoord.txt")
coord
coord[1]
coord <437755
?value
coord <- data.matrix(coord)
attach(coord)
coord <- read.table("pumacoord.txt")
colnames(coord) <- c("x","y")
attach(coord)
x
y
colnames(coord) <- c("x","y")
attach(coord)
1
x
rm(x)
ls()
rm(list=ls())
ls()
setwd("/Users/karljarvis/Documents/_NAU/Classes/R/pumas/Geneland/")#
geno <- read.table("pumageno.txt")#
coord <- read.table("pumacoord.txt")
colnames(coord) <- c("x","y")
x
y
coord.n <- coord[which(x <437755)]
setwd("/Users/karljarvis/Documents/_NAU/Classes/R/pumas/Geneland/")#
geno <- read.table("pumageno.txt")#
coord <- read.table("pumacoord.txt")
detach(coord)
coord.n <- coord[which(coord$x<437755)]
coord.n
summary(coord)
coord.n <- coord[which(coord$x<469484)]
coord.n
coord.n <- coord[which(coord$y>0 & coord$x < 469484)]
coord.n
test.c1 <- c(1,2,3,4,5)
test.c2 <- c(2,4,6,8,10)
test <- cbind(test.c1,test.c2)
test
test.sub <- test[ which(test$test.c1 >3)]
coord.n <- coord[which(coord$y>0 & coord$x < 469484),]
coord.n
coord.n <- coord[which(coord$x < 469484),]
coord.n
p <- 0.7
q <- 1-p
q
na1 <- n*fa1
n <- 100
fa1 <- 0.7
fa2 <- 1-a1
fa2 <- 1-fa1
na1 <- n*fa1
na2 <- n*fa2
na1
na2
g1a <- rep(1,n)
g1b <- rep(1,n)
g1a
g1a <- seq(1,n)
g1a
g1a <- rep(0,n)
g1b <- rep(0,n)
g1a
g1b
allelepool <- c(rep(a1,fa1*n*2),rep(a2,fa2*n*2))
allelepool <- c(rep("a1",fa1*n*2),rep("a2",fa2*n*2))
allelepool
?sample
allelepool
allelepool <- c(rep("a1",fa1*n),rep("a2",fa2*n))
g1a <- sample(allelepool,n,replace=FALSE)
g1a
?sample
n <- 100#
#
# define allele frequency#
fa1 <- 0.7#
fa2 <- 1-fa1#
#
# make an allele pool from which alleles will be sampled#
allelepool <- c("a1","a2")#
#
# make vectors to hold the alleles#
g1a <- sample(allelepool,n,replace=TRUE,prob=c(fa1,fa2))
g1a
g1a$a1
g1a[a1]
g1a["a1"]
?count
g1a <- sample(allelepool,n,replace=TRUE,prob=c(fa1,fa2))
g1b <- sample(allelepool,n,replace=TRUE,prob=c(fa1,fa2))
g1a
g1b
allelepool <- c(1,2)#
#
# make vectors to hold the alleles#
g1a <- sample(allelepool,n,replace=TRUE,prob=c(fa1,fa2))#
g1b <- sample(allelepool,n,replace=TRUE,prob=c(fa1,fa2))
g1a
g1a[1]
g1a[2]
g1a[5]
g1a[x>2]
g1a[g1a>2]
g1a[g1a>1]
g1ab <- cbind(g1a,g1b)
g1ab
allelepool <- c(rep(1,fa1*n),rep(2,fa2*n))
allelepool
g1ab <- cbind(g1a,g1b)
sum(g1a[g1a=1])
length(g1a[g1a=1])
g1a[g1a=1]
g1a[g1a>0]
g1a[g1a>1]
length[g1ab>1]
g1ab <- cbind(g1a,g1b)
length[g1ab>1]
length[g1a>1]
length(g1a[g1a>1])
length(g1b[g1b>1])
n <- 100#
#
# define alleles#
a1 <- "1"#
a2 <- "2"#
a3 <- "3"#
a4 <- "4"#
a5 <- "5"#
a6 <- "6"#
a7 <- "7"#
a8 <- "8"#
#
# define allele frequency#
fa1 <- 0.1#
fa2 <- 0.1#
fa3 <- 0.01#
fa4 <- 0.3#
fa5 <- 0.05#
fa6 <- 0.05#
fa7 <- 0.05#
fa8 <- 1 - sum(fa1,fa2,fa3, fa4, fa5, fa6, fa7)
fa8
n <- 100#
#
# define alleles and frequencies#
a1 <- "1"#
a2 <- "2"#
fa1 <- 0.7#
fa2 <- 1-fa1
a1
a2
fa1
fa2
allelepool <- c(rep(a1, fa1*n*2), rep(a2,fa2*n*2))
allelepool
a.allelepool <- c(rep(a1, fa1*n*2), rep(a2,fa2*n*2))#
#
# sample from the pool to get genotypes#
a.genopool <- sample(a.allelepool,n*2,replace=FALSE)
a.genopool
?as.matrix
a.geno <- as.matrix(a.genopool, nrow=n, ncol=2)
a.geno
?as.matrix
n <- 100#
#
# define alleles and frequencies#
a1 <- 5#
a2 <- 7#
fa1 <- 0.7#
fa2 <- 1-fa1#
#
# make an allele pool from which alleles will be sampled#
a.allelepool <- c(rep(a1, fa1*n*2), rep(a2,fa2*n*2))#
#
# sample from the pool to get genotypes#
a.genopool <- sample(a.allelepool,n*2,replace=FALSE)#
#
# format as 2 columns#
a.geno <- as.matrix(a.genopool, nrow=n, ncol=2)
a.geno
library(picante)
?ses.mpd
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")#
phy <- read.tree("mycphy.tree")#
plot(phy)#
comm <- data.matrix(read.table("myccom.txt"))#
#
# prune tree - we don't have the need for this#
#comm.phy <- prune.sample(comm,phy) # cuts down the phylogeny to include only what's in the community#
#comm.phy#
#
##################################
# Faith's Phylogenetic Diversity#
##################################
# regular PD#
pd.phy <- pd(comm, phy, include.root = TRUE); pd.phy #
write.table(pd.phy,"phylodiv.txt")#
#
# standardized PD, richness null model#
ses.pd.phy.richness <- ses.pd(comm, phy, null.model="richness", runs=999)#
write.table(ses.pd.phy.richness,"PD_stand_richness.txt")#
#
# standardized PD, Gotelli null model#
#ses.pd.phy.indswap <- ses.pd(comm, phy, null.model="independentswap", runs=999, iterations=1000)#
#
##################################
# NRI #
##################################
# abundance not weighted#
phydist <- cophenetic(phy)#
ses.mpd.myco.uw <- ses.mpd(comm, phydist, null.model = 'taxa.labels', abundance.weighted = FALSE, runs = 999); ses.mpd.myco.uw#
write.table(ses.mpd.myco.uw,"NRI_unweighted.txt")#
#
# abundance weighted#
phydist <- cophenetic(phy)#
ses.mpd.myco.w <- ses.mpd(comm, phydist, null.model = 'taxa.labels', abundance.weighted = TRUE, runs = 999); ses.mpd.myco.w#
write.table(ses.mpd.myco.w,"NRI_weighted.txt")#
#
# abundance not weighted#
phydist <- cophenetic(phy)#
ses.mpd.myco.uw <- ses.mpd(comm, phydist, null.model = 'richness', abundance.weighted = FALSE, runs = 999); ses.mpd.myco.uw#
write.table(ses.mpd.myco.uw,"NRI_unweighted_rich.txt")#
#
# NRI - abundance weighted#
phydist <- cophenetic(phy)#
ses.mpd.myco.w <- ses.mpd(comm, phydist, null.model = 'richness', abundance.weighted = TRUE, runs = 999); ses.mpd.myco.w#
write.table(ses.mpd.myco.w,"NRI_weighted_rich.txt")#
#
##################################
# NTI #
##################################
# abundance not weighted#
phydist <- cophenetic(phy)#
ses.mntd.myco.uw <- ses.mntd(comm, phydist, null.model = 'taxa.labels', abundance.weighted = FALSE, runs = 999); ses.mntd.myco.uw#
write.table(ses.mntd.myco.uw,"NRI_unweighted.txt")#
#
# NRI - abundance weighted#
phydist <- cophenetic(phy)#
ses.mntd.myco.w <- ses.mntd(comm, phydist, null.model = 'taxa.labels', abundance.weighted = TRUE, runs = 999); ses.mntd.myco.w#
write.table(ses.mntd.myco.w,"NRI_weighted.txt")#
#
##################################
# Phylogenetic Beta Diversity#
##################################
# not abundance weighted#
comdist.result.uw <- comdist(comm, phydist, abundance.weighted=FALSE)#
comdist.result.uw#
library(cluster)#
comdist.clusters.uw <- hclust(comdist.result.uw)#
plot(comdist.clusters.uw, cex=0.5)#
#
# abundance weighted#
comdist.result <- comdist(comm, phydist, abundance.weighted=TRUE)#
comdist.result.w#
library(cluster)#
comdist.clusters.w <- hclust(comdist.result.w)#
plot(comdist.clusters.w, cex=0.5)#
write(comdist.result.w, "phylobeta.txt", ncol=nrow(comm))
plot(comdist.clusters.w, cex=0.5)
phydist <- cophenetic(phy)
?ses.pd
pd.phy <- pd(comm, phy, include.root = TRUE); pd.phy #
write.table(pd.phy,"phylodiv.txt")#
#
# standardized PD, richness null model#
ses.pd.phy.richness <- ses.pd(comm, phy, null.model="richness", runs=999)#
write.table(ses.pd.phy.richness,"PD_stand_richness.txt")
phydist <- cophenetic(phy)#
ses.mntd.myco.uw <- ses.mntd(comm, phydist, null.model = 'taxa.labels', abundance.weighted = FALSE, runs = 999); ses.mntd.myco.uw#
write.table(ses.mntd.myco.uw,"NTI_unweighted.txt")#
#
# abundance weighted#
phydist <- cophenetic(phy)#
ses.mntd.myco.w <- ses.mntd(comm, phydist, null.model = 'taxa.labels', abundance.weighted = TRUE, runs = 999); ses.mntd.myco.w#
write.table(ses.mntd.myco.w,"NTI_weighted.txt")
library(picante)
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")#
phy <- read.tree("mycphy.tree")#
plot(phy)#
comm <- data.matrix(read.table("myccom.txt"))
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")#
phy <- read.tree("myco.phy")#
plot(phy)#
comm <- data.matrix(read.table("myccomf.txt"))
pd.phy <- pd(comm, phy, include.root = TRUE); pd.phy
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")#
phy <- read.tree("myco.phy")#
plot(phy)#
comm <- data.matrix(read.table("myccomf.txt"))
pd.phy <- pd(comm, phy, include.root = TRUE); pd.phy #
write.table(pd.phy,"phylodivul.txt")
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")#
phy <- read.tree("myco.phy")#
plot(phy)#
comm <- data.matrix(read.table("myccomf.txt"))
pd.phy <- pd(comm, phy, include.root = TRUE); pd.phy #
write.table(pd.phy,"phylodivul.txt")
comdist.result.w <- comdist(comm, phydist, abundance.weighted=TRUE)#
comdist.result.w
library(picante)
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")#
phy <- read.tree("myco.phy")#
plot(phy)#
comm <- data.matrix(read.table("myccomf.txt"))
comdist.result.w <- comdist(comm, phydist, abundance.weighted=TRUE)#
comdist.result.w#
library(cluster)#
comdist.clusters.w <- hclust(comdist.result.w)#
plot(comdist.clusters.w, cex=0.5)#
write(comdist.result.w, "phylobeta.txt", ncol=nrow(comm))
phydist <- cophenetic(phy)
comdist.result.w <- comdist(comm, phydist, abundance.weighted=TRUE)#
comdist.result.w
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")#
phy <- read.tree("mycphy.tree")#
plot(phy)#
comm <- data.matrix(read.table("myccom.txt"))
phydist <- cophenetic(phy)
comdist.result.w <- comdist(comm, phydist, abundance.weighted=TRUE)#
comdist.result.w#
library(cluster)#
comdist.clusters.w <- hclust(comdist.result.w)#
plot(comdist.clusters.w, cex=0.5)#
write(comdist.result.w, "phylobeta.txt", ncol=nrow(comm))
phy <- read.tree("mycultra.phy")
plot(phy)
phydist <- cophenetic(phy)
comdist.result.w <- comdist(comm, phydist, abundance.weighted=TRUE)#
comdist.result.w#
library(cluster)#
comdist.clusters.w <- hclust(comdist.result.w)#
plot(comdist.clusters.w, cex=0.5)#
write(comdist.result.w, "phylobeta.txt", ncol=nrow(comm))
phydist <- cophenetic(phy)#
ses.mpd.myco.w <- ses.mpd(comm, phydist, null.model = 'richness', abundance.weighted = TRUE, runs = 999); ses.mpd.myco.w
phylosor.result <- phylosor(comm,phy)#
phylosor.clusters <- hclust(phylosor.result)#
plot(phylosor.clusters, cex=0.5)#
#
##################################
# Unifrac -unweighted#
##################################
unifrac.result <- unifrac(comm,phy)
unifrac.result
phylosor.result
comdistnt.result.uw <- comdistnt(comm, phydist, abundance.weighted=FALSE)#
comdistnt.result.uw#
library(cluster)#
comdistnt.clusters.uw <- hclust(comdistnt.result.uw)#
plot(comdistnt.clusters.uw, cex=0.5)
plot(phy)
library(picante)
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")
phy <- read.tree("mycultra.phy")
plot(phy)
library(ape)
vignette(ape)
?ape
library(picante)
setwd("/Users/karljarvis/Documents/_NAU/Classes/G2E/Phylomeet/Analysis/myco")
phy <- read.tree("mycultra.phy")
plot(phy)
